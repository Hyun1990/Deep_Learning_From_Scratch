

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>6. 卷积神经网络 &mdash; Deep_Learning_From_Scratch 1.0 文档</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="索引"
              href="genindex.html"/>
        <link rel="search" title="搜索" href="search.html"/>
    <link rel="top" title="Deep_Learning_From_Scratch 1.0 文档" href="index.html"/>
        <link rel="prev" title="5. 与学习相关的技巧" href="与学习相关的技巧.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Deep_Learning_From_Scratch
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="感知机.html">1. 感知机</a></li>
<li class="toctree-l1"><a class="reference internal" href="神经网络.html">2. 神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="神经网络的学习.html">3. 神经网络的学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="误差反向传播法.html">4. 误差反向传播法</a></li>
<li class="toctree-l1"><a class="reference internal" href="与学习相关的技巧.html">5. 与学习相关的技巧</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">6. 卷积神经网络</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">6.1. 整体结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">6.2. 卷积层</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">6.3. 池化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id5">6.4. 卷积层和池化层的实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cnn">6.5. CNN的实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id6">6.6. 具有代表性的CNN</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Deep_Learning_From_Scratch</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>6. 卷积神经网络</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/卷积神经网络.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>6. 卷积神经网络<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<div class="section" id="id2">
<h2>6.1. 整体结构<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<blockquote>
<div><p>全连接神经网络中，Affine曾后面跟着激活函数ReLU层（或Sigmoid层）</p>
<img alt="_images/full.png" class="align-center" src="_images/full.png" />
<p>CNN中新增了Convolution层和Pooling层</p>
<img alt="_images/CNN.png" class="align-center" src="_images/CNN.png" />
</div></blockquote>
</div>
<div class="section" id="id3">
<h2>6.2. 卷积层<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><strong>全连接层存在的问题</strong></li>
</ul>
<blockquote>
<div>全连接层存在什么问题呢？那就是数据的形状被“忽视”了。比如，输入数据是图像时，图像通常是高，长，通道方向上的3维形状。但是全连接层输入时，需要将3维数据拉平为1维数据。</div></blockquote>
<ul class="simple">
<li><strong>卷积运算</strong></li>
</ul>
<blockquote>
<div><p>卷积运算相当于图像处理中的“滤波器运算”。</p>
<img alt="_images/conv.png" class="align-center" src="_images/conv.png" />
<img alt="_images/conv_bias.png" class="align-center" src="_images/conv_bias.png" />
</div></blockquote>
<ul class="simple">
<li><strong>填充</strong></li>
</ul>
<blockquote>
<div><p>在卷积运算之前，有时要向输入数据的周围填入固定的数据（比如0等），这称为填充。使用填充主要时为了调整输出的大小。因为每次进行卷积运算都会缩小空间，那么在某个时刻输出大小就有可能会变为1，导致无法再应用卷积运算。</p>
<img alt="_images/padding.png" class="align-center" src="_images/padding.png" />
</div></blockquote>
<ul class="simple">
<li><strong>步幅</strong></li>
</ul>
<blockquote>
<div><p>应用滤波器的位置间隔成为步幅(stride)。</p>
<img alt="_images/stride.png" class="align-center" src="_images/stride.png" />
<p>假设输入大小为
<span class="math">\((H,W)\)</span>
，滤波器的大小为
<span class="math">\((FH,FW)\)</span>
，输出大小为
<span class="math">\((OH,OW)\)</span>
, 填充为
<span class="math">\(P\)</span>
，步幅为
<span class="math">\(S\)</span>
，此时输出大小可以通过下式计算：</p>
<div class="math">
\[\begin{split}OH = \frac{H + 2P -FH}{S} + 1\\
OW = \frac{H + 2P -FH}{S} + 1\end{split}\]</div>
</div></blockquote>
<ul class="simple">
<li><strong>三维数据的卷积运算</strong></li>
</ul>
<blockquote>
<div><img alt="_images/conv_3.png" class="align-center" src="_images/conv_3.png" />
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>将数据和滤波器结合长方体来考虑，3维数据的卷积运算会很容易理解。比如，通道数为C，高度为H，长度为W的数据形状可以写成(C, H, W)。</p>
<img alt="_images/block_conv.png" class="align-center" src="_images/block_conv.png" />
</div></blockquote>
<div class="line-block">
<div class="line"><br /></div>
</div>
<blockquote>
<div><p>如果需要在通道方向上也拥有多个卷积运算的输出，就需要用到多个滤波器（权重）。用图表示如下：</p>
<img alt="_images/muti_conv.png" class="align-center" src="_images/muti_conv.png" />
</div></blockquote>
<div class="line-block">
<div class="line"><br /></div>
</div>
<blockquote>
<div><p>加偏置</p>
<img alt="_images/muti_bias.png" class="align-center" src="_images/muti_bias.png" />
</div></blockquote>
<ul class="simple">
<li><strong>批处理</strong></li>
</ul>
<blockquote>
<div><img alt="_images/batch_conv.png" class="align-center" src="_images/batch_conv.png" />
</div></blockquote>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="id4">
<h2>6.3. 池化层<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h2>
<blockquote>
<div><p>池化是缩小高，长方向上的空间运算。下图为Max池化的处理顺序。</p>
<img alt="_images/pool.png" class="align-center" src="_images/pool.png" />
<p>除了Max池化外还有Average池化。Max是从目标区域中取出最大值，Average是计算目标区域中的平均值。</p>
</div></blockquote>
<ul class="simple">
<li><strong>池化层的特征</strong></li>
</ul>
<blockquote>
<div><ol class="arabic simple">
<li>没有要学习的参数</li>
<li>通道数不发生变化</li>
<li>对微小的位置变化具有鲁棒性</li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id5">
<h2>6.4. 卷积层和池化层的实现<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><strong>基于im2col的展开</strong></li>
</ul>
<blockquote>
<div><p>im2col这个名称是“image to column”的缩写，对于输入数据，im2col将应用滤波器的区域横向展开为1列。</p>
<img alt="_images/im2col.png" class="align-center" src="_images/im2col.png" />
<p>卷积运算的滤波器处理细节：将滤波器纵向展开为1列，并计算和im2col展开的数据的矩阵乘积，最后转换(reshape)为输出数据的大小。</p>
</div></blockquote>
<ul class="simple">
<li><strong>卷积层的实现</strong></li>
</ul>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Convolution</span><span class="p">:</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>

        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
                <span class="n">FN</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">FH</span><span class="p">,</span> <span class="n">FW</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">out_h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">-</span> <span class="n">FH</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
                <span class="n">out_w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">W</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">-</span> <span class="n">FW</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>

                <span class="n">col</span> <span class="o">=</span> <span class="n">im2col</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">FH</span><span class="p">,</span> <span class="n">FW</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">)</span>
                <span class="n">col_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">FN</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="c1"># 滤波器的展开</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">col_w</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>

                <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">out_h</span><span class="p">,</span> <span class="n">out_w</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

                <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div></blockquote>
<ul class="simple">
<li><strong>池化层的实现</strong></li>
</ul>
<blockquote>
<div><p>池化层的实现和卷积层相同，都使用im2col展开数据。不过，池化的情况下，在通道方向上是独立的，这点和卷积层不同。</p>
<img alt="_images/pool_realize.png" class="align-center" src="_images/pool_realize.png" />
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Pooling</span><span class="p">:</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_h</span><span class="p">,</span> <span class="n">pool_w</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pool_h</span> <span class="o">=</span> <span class="n">pool_h</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pool_w</span> <span class="o">=</span> <span class="n">pool_w</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>

        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
                <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">out_h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_h</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
                <span class="n">out_w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_w</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>

                <span class="c1"># 展开</span>
                <span class="n">col</span> <span class="o">=</span> <span class="n">im2col</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">)</span>
                <span class="n">col</span> <span class="o">=</span> <span class="n">col</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_h</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">pool_w</span><span class="p">)</span>

                <span class="c1"># 最大值</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="c1"># 转换</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">out_h</span><span class="p">,</span> <span class="n">out_w</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

                <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="cnn">
<h2>6.5. CNN的实现<a class="headerlink" href="#cnn" title="永久链接至标题">¶</a></h2>
<blockquote>
<div><img alt="_images/simple_cnn.png" class="align-center" src="_images/simple_cnn.png" />
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleConvNet</span><span class="p">:</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
                        <span class="n">conv_param</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;filter_num&#39;</span><span class="p">:</span><span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;filter_size&#39;</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span>
                                    <span class="s1">&#39;pad&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;stride&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span>
                        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">weight_init_std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
                <span class="n">filter_num</span> <span class="o">=</span> <span class="n">conv_param</span><span class="p">[</span><span class="s1">&#39;filter_num&#39;</span><span class="p">]</span>
                <span class="n">filter_size</span> <span class="o">=</span> <span class="n">conv_param</span><span class="p">[</span><span class="s1">&#39;filter_size&#39;</span><span class="p">]</span>
                <span class="n">filter_pad</span> <span class="o">=</span> <span class="n">conv_param</span><span class="p">[</span><span class="s1">&#39;pad&#39;</span><span class="p">]</span>
                <span class="n">filter_stride</span> <span class="o">=</span> <span class="n">conv_param</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">]</span>
                <span class="n">input_size</span> <span class="o">=</span> <span class="n">input_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">conv_output_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_size</span> <span class="o">-</span> <span class="n">filter_size</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">filter_pad</span><span class="p">)</span> <span class="o">/</span> \
                                    <span class="n">filter_stride</span> <span class="o">+</span><span class="mi">1</span>
                <span class="n">pool_output_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">filter_num</span> <span class="o">*</span> <span class="p">(</span><span class="n">conv_output_size</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span>
                                   <span class="p">(</span><span class="n">conv_output_size</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> \
                                    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">filter_num</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                        <span class="n">filter_size</span><span class="p">,</span> <span class="n">filter_size</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;b1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">filter_num</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> \
                                    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">pool_output_size</span><span class="p">,</span>
                                                        <span class="n">hidden_size</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;b2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> \
                                    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;b3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Conv1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W1&#39;</span><span class="p">],</span>
                                                   <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;b1&#39;</span><span class="p">],</span>
                                                   <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">],</span>
                                                   <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;pad&#39;</span><span class="p">])</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Relu1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Relu</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Pool1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Pooling</span><span class="p">(</span><span class="n">pool_h</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pool_w</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Affine1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Affine</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W2&#39;</span><span class="p">],</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;b2&#39;</span><span class="p">])</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Relu2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Relu</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Affine2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Affine</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W3&#39;</span><span class="p">],</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;b3&#39;</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">last_layer</span> <span class="o">=</span> <span class="n">softmaxwithloss</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                        <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">x</span>

        <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
                <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lastLayer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
                <span class="c1"># forward</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

                <span class="c1"># backward</span>
                <span class="n">dout</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">dout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lastLayer</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>

                <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
                        <span class="n">dout</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>

                <span class="c1"># 设定</span>
                <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;W1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Conv1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dW</span>
                <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;b1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Conv1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">db</span>
                <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;W2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Affine1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dW</span>
                <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;b2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Affine1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">db</span>
                <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;W3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Affine2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dW</span>
                <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;b3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s1">&#39;Affine2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">db</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="id6">
<h2>6.6. 具有代表性的CNN<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><strong>LeNet</strong></li>
</ul>
<blockquote>
<div><img alt="_images/lenet.png" class="align-center" src="_images/lenet.png" />
<p>和“现在的CNN”相比，LeNet中使用sigmoid函数，而现在的CNN中主要使用ReLU函数。此外，原始的LeNet中使用子采样(subsampling)缩小中间数据的大小，而现在的CNN中Max池化是主流。</p>
</div></blockquote>
<ul class="simple">
<li><strong>AlexNet</strong></li>
</ul>
<blockquote>
<div><img alt="_images/alexnet.png" class="align-center" src="_images/alexnet.png" />
<p>AlexNet叠有多个卷积层和池化层，最后经由全连接层输出结果。虽然结构上AlexNet和LeNet没有大的不同，但有以下几点差异：</p>
<ol class="arabic simple">
<li>激活函数使用ReLU</li>
<li>使用进行局部正规化的LRN(Local Response Normalization)层</li>
<li>使用Rropout</li>
</ol>
</div></blockquote>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="与学习相关的技巧.html" class="btn btn-neutral" title="5. 与学习相关的技巧" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, hyun.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>